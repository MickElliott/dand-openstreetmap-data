{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenStreetMap Dataset\n",
    "This OpenStreetMap Dataset notebook was created for the final project of the _Data Wrangling with MongoDB_ Udacity course. \n",
    "Specifically, this project is the _OpenStreetMap Data_ project. \n",
    "\n",
    "This notebook forms an analysis of an OpenStreetMap dataset. OpenStreetMap is a collaborative project to create a free editable map of the world. The data generated by the OpenStreetMap project is considered its primary output, rather than the map itself. The data can be used in a variety of applications in place of propriety datasources. Data can be downloaded from the OSM website in different formats, including XML. This dataset was obtained from the [Metro Extracts section](https://mapzen.com/data/metro-extracts/metro/sydney_australia/) of the OpenStreetMap website. It is the Sydney, Australia metro extract.\n",
    "\n",
    "This dataset can be investigated and wrangled with the purpose of preparing it for entering into a MongoDB NoSQL collection.\n",
    "\n",
    "The _Data Wrangling with MongoDB_ course serves as one of the courses leading to the Udacity Data Analyst Nanodegree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate the Dataset\n",
    "### Elements\n",
    "Find what elements are present in the XML data file and how many of each type. We use iterative parsing to process the map file to avoid loading the whole file into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bounds': 1,\n",
       " 'member': 71110,\n",
       " 'nd': 1755778,\n",
       " 'node': 1461112,\n",
       " 'osm': 1,\n",
       " 'relation': 5179,\n",
       " 'tag': 839841,\n",
       " 'way': 200653}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xml.etree.cElementTree as ET\n",
    "\n",
    "filename = \"sydney_australia.osm\"\n",
    "elements = {}\n",
    "for event, elem in ET.iterparse(filename):\n",
    "    tag = elem.tag\n",
    "    if tag in elements:\n",
    "        elements[tag] += 1\n",
    "    else:\n",
    "        elements[tag] = 1\n",
    "elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the documentation, OpenStreetMap uses a topological data structure, with mapping points represented by three core elements:\n",
    "* __Nodes__ are points with a geographic position\n",
    "* __Ways__ are ordered lists of nodes\n",
    "* __Relations__ are ordered lists of nodes\n",
    "\n",
    "In addition, __tags__ are sub-elements which are used to store metadata about their respective map objects. Tag data is stored in key-value pairs.\n",
    "\n",
    "### Tags\n",
    "Investigate what tags are present in the XML data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tag types found: 1859\n",
      "Printing the first 20 results:\n",
      "('highway', 146486)\n",
      "('name', 100696)\n",
      "('source', 97995)\n",
      "('building', 39895)\n",
      "('surface', 25754)\n",
      "('maxspeed', 24982)\n",
      "('oneway', 20365)\n",
      "('addr:street', 18864)\n",
      "('amenity', 18144)\n",
      "('source:name', 13595)\n",
      "('noname', 12472)\n",
      "('created_by', 12330)\n",
      "('foot', 12009)\n",
      "('leisure', 11852)\n",
      "('addr:housenumber', 10191)\n",
      "('bicycle', 10186)\n",
      "('addr:postcode', 8056)\n",
      "('service', 8024)\n",
      "('lanes', 7813)\n",
      "('ref', 7248)\n"
     ]
    }
   ],
   "source": [
    "tags = {}\n",
    "for event, element in ET.iterparse(filename):\n",
    "    if element.tag == \"tag\":\n",
    "        key = element.attrib['k']\n",
    "        if key in tags:\n",
    "            tags[key] += 1\n",
    "        else:\n",
    "            tags[key] = 1\n",
    "print(\"Number of tag types found: %d\" % len(tags))\n",
    "sorted_tags = sorted(tags.items(), reverse=True, key=lambda (k,v): (v,k))\n",
    "\n",
    "print \"Printing the first 20 results:\"\n",
    "for i in range(0, 20):\n",
    "    print sorted_tags[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The dataset contains 1859 types of tags. Of particular note, is the fact that address information is spread over multiple tags. Each tag name being prefixed with \"addr:\". This data may need to be wrangled before being entered into the MongoDB database.\n",
    "\n",
    "### Address tags\n",
    "Investigate the various types of tags used for address data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of address tag types found: 29\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('addr:street', 18864),\n",
       " ('addr:housenumber', 10191),\n",
       " ('addr:postcode', 8056),\n",
       " ('addr:city', 6517),\n",
       " ('addr:country', 2177),\n",
       " ('addr:state', 1735),\n",
       " ('addr:suburb', 1556),\n",
       " ('addr:housename', 320),\n",
       " ('addr:province', 273),\n",
       " ('addr:interpolation', 178),\n",
       " ('addr:place', 109),\n",
       " ('addr:unit', 39),\n",
       " ('addr:floor', 13),\n",
       " ('addr:source:housenumber', 7),\n",
       " ('addr:shop', 5),\n",
       " ('addr:suite', 3),\n",
       " ('addr:street:source', 2),\n",
       " ('addr:level', 2),\n",
       " ('addr:flats', 2),\n",
       " ('addr:city_1', 2),\n",
       " ('addr:street_1', 1),\n",
       " ('addr:room', 1),\n",
       " ('addr:number', 1),\n",
       " ('addr:lot', 1),\n",
       " ('addr:inclusion', 1),\n",
       " ('addr:housenumber_1', 1),\n",
       " ('addr:housenumber:source', 1),\n",
       " ('addr:full', 1),\n",
       " ('addr:building', 1)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addrs = {}\n",
    "for key in tags:\n",
    "    if key[:5] == \"addr:\":\n",
    "        addrs[key] = tags[key]\n",
    "\n",
    "print(\"Number of address tag types found: %d\" % len(addrs))\n",
    "sorted(addrs.items(), reverse=True, key=lambda (k,v): (v,k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "29 types of address tags are present in the dataset.\n",
    "\n",
    "## Investigate Potential Problems\n",
    "Before the data is processed and entered into the database, we check the attributes\n",
    "of each tag and see if there are any potential problems. We use regular expressions to search for certain patterns in the tags that could be problematic and need cleaning. We investigate how many other tags use colons to create sub-tags and how many tags contain potential problem characters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lower_case': 731819,\n",
       " 'lower_case_with_colon': 99458,\n",
       " 'other': 8557,\n",
       " 'problem_chars': 7}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "lower_case = re.compile(r'^([a-z]|_)*$')\n",
    "lower_case_with_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n",
    "problem_chars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "keys = {\"lower_case\": 0, \n",
    "        \"lower_case_with_colon\": 0, \n",
    "        \"problem_chars\": 0, \n",
    "        \"other\": 0}\n",
    "problem_tags = {}\n",
    "colon_tags = {}\n",
    "other_tags = {}\n",
    "\n",
    "for event, element in ET.iterparse(filename):\n",
    "    if element.tag == \"tag\":\n",
    "        if 'k' in element.attrib:\n",
    "            k = element.attrib['k']\n",
    "            if re.search(lower_case, k):\n",
    "                keys[\"lower_case\"] += 1\n",
    "            elif re.search(lower_case_with_colon, k):\n",
    "                keys[\"lower_case_with_colon\"] += 1\n",
    "                \n",
    "                if k in colon_tags:\n",
    "                    colon_tags[k] += 1\n",
    "                else:\n",
    "                    colon_tags[k] = 1\n",
    "            elif re.search(problem_chars, k):\n",
    "                keys[\"problem_chars\"] += 1\n",
    "                \n",
    "                if k in problem_tags:\n",
    "                    problem_tags[k] += 1\n",
    "                else:\n",
    "                    problem_tags[k] = 1\n",
    "            else:\n",
    "                keys[\"other\"] += 1\n",
    "                \n",
    "                if k in other_tags:\n",
    "                    other_tags[k] += 1\n",
    "                else:\n",
    "                    other_tags[k] = 1\n",
    "\n",
    "keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are only 7 tags with characters that could be problematic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Hours of Operation': 2,\n",
       " 'Old Fox Name': 1,\n",
       " 'Payments Accepted': 1,\n",
       " 'acma.gov.au:site_id': 1,\n",
       " 'entrance:loading dock': 1,\n",
       " 'old Fox Name': 1}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problem_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "None of these tags contain important information so tags with problematic characters in the tag name can be safely ignored. We need to look at tags which contain colons in their names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing the first 20 results:\n",
      "('addr:street', 18864)\n",
      "('source:name', 13595)\n",
      "('addr:housenumber', 10191)\n",
      "('addr:postcode', 8056)\n",
      "('addr:city', 6517)\n",
      "('is_in:suburb', 4093)\n",
      "('source:location', 3910)\n",
      "('source:maxspeed', 3220)\n",
      "('addr:country', 2177)\n",
      "('source:geometry', 2152)\n",
      "('name:en', 2117)\n",
      "('building:levels', 2113)\n",
      "('source:date', 1873)\n",
      "('addr:state', 1735)\n",
      "('ref:start_date', 1622)\n",
      "('addr:suburb', 1556)\n",
      "('nswlpi:cadid', 731)\n",
      "('source:sport', 594)\n",
      "('ref:nswgnb', 518)\n",
      "('place:nswgnb', 518)\n"
     ]
    }
   ],
   "source": [
    "sorted_tags = sorted(colon_tags.items(), reverse=True, key=lambda (k,v): (v,k))\n",
    "\n",
    "print \"Printing the first 20 results:\"\n",
    "for i in range(0, 20):\n",
    "    print sorted_tags[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Principally of note are the tags with address information. Another tag that would be valuable is the \"is_in:suburb\" tag. Some prominent locations don't have address information recorded but have an \"is_in:suburb\" tag. All other tags with colons will be ignored.\n",
    "\n",
    "We need to investigate the other types of tag names that will be encountered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing the first 20 results:\n",
      "('source:name:date', 4418)\n",
      "('source:sport:date', 310)\n",
      "('building:roof:shape', 196)\n",
      "('parking:lane:both:parallel', 193)\n",
      "('Origin_Z', 165)\n",
      "('Origin_Y', 165)\n",
      "('Origin_X', 165)\n",
      "('Item_class', 165)\n",
      "('turn:lanes:forward', 160)\n",
      "('turn:lanes:backward', 156)\n",
      "('Item_ID', 145)\n",
      "('parking:lane:both', 125)\n",
      "('Floor_Coun', 116)\n",
      "('Room_Count', 67)\n",
      "('parking:lane:left', 63)\n",
      "('parking:lane:both:width', 59)\n",
      "('shoulder:left:width', 57)\n",
      "('shoulder:right:width', 54)\n",
      "('parking:lane:left:parallel', 53)\n",
      "('cycleway:lane:width', 52)\n"
     ]
    }
   ],
   "source": [
    "sorted_tags = sorted(other_tags.items(), reverse=True, key=lambda (k,v): (v,k))\n",
    "\n",
    "print \"Printing the first 20 results:\"\n",
    "for i in range(0, 20):\n",
    "    print sorted_tags[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that some tags have multiple colons in their name. We don't need this information so we will ignore all tags with more than one colon in the name.\n",
    "\n",
    "## Inconsistencies in the data\n",
    "### Street Types\n",
    "Any dataset which contains address information will have inconsistant naming conventions, especially for street types. For example, a road could be called 'Road', 'Rd' or 'Rd.' We will make a list of all street types and look for inconsistencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing the first 20 results:\n",
      "('Street', 8783)\n",
      "('Road', 4525)\n",
      "('Avenue', 2997)\n",
      "('Parade', 469)\n",
      "('Drive', 396)\n",
      "('Place', 319)\n",
      "('Crescent', 273)\n",
      "('Highway', 245)\n",
      "('Circuit', 169)\n",
      "('Lane', 83)\n",
      "('Wolli', 74)\n",
      "('Court', 52)\n",
      "('Way', 46)\n",
      "('Esplanade', 36)\n",
      "('Close', 33)\n",
      "('Boulevard', 29)\n",
      "('Broadway', 25)\n",
      "('Berith', 25)\n",
      "('West', 20)\n",
      "('St', 20)\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Use a regular expression to extract the street type from the \"addr:street\" tag.\n",
    "street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "\n",
    "def is_street_name(elem):\n",
    "    return (elem.tag == \"tag\") and (elem.attrib['k'] == \"addr:street\")\n",
    "\n",
    "street_types = defaultdict(int)\n",
    "for event, elem in ET.iterparse(filename):\n",
    "    if is_street_name(elem):\n",
    "        m = street_type_re.search(elem.attrib['v'])\n",
    "        if m:\n",
    "            street_type = m.group()\n",
    "            street_types[street_type] += 1\n",
    "        \n",
    "sorted_tags = sorted(street_types.items(), reverse=True, key=lambda (k,v): (v,k))\n",
    "\n",
    "print \"Printing the first 20 results:\"\n",
    "for i in range(0, 20):\n",
    "    print sorted_tags[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The list of street types shows some inconsistency in the use of Street, Avenue, Road and Place. The abbreviations 'St', 'St.', 'street', 'st' and even 'Streett' are used for Street. Steps will be taken in the data wrangling phase to remove these abbreviations and make the naming of ways more consistent.\n",
    "\n",
    "### Apartment numbering\n",
    "Another inconsistency found in Australian addresses is the way that apartment numbers are represented. For example, apartment 3 at housenumber 42 can be represented as 'Unit 3, 42', '3/42', '3-42', etc. We can see this when we investigate housenumber tags that have a value which contains non-alphanumeric characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing the first 50 results:\n",
      "412-414 George St\n",
      "9/10\n",
      "B01/262\n",
      "Shop P48\n",
      "Building 15 177-219\n",
      "7/40\n",
      "suite 5/68\n",
      "3/156-158\n",
      "69/1\n",
      "Shop 5, 39-53\n",
      "12/15-13\n",
      "Shop 2-3, 348\n",
      "1/63-71\n",
      "26/29-13\n",
      "Shop 6/11-13\n",
      "1/417\n",
      "3/194-196\n",
      "518/50\n",
      "Shop 21, 230\n",
      "W2C1/75-85\n",
      "Shop 202, 24-32\n",
      "2/52\n",
      "2/400\n",
      "63/919\n",
      "2/19-21\n",
      "1/54\n",
      "370, Suite 30\n",
      "11/19-21\n",
      "54, Suite 202\n",
      "C1, 85-113\n",
      "1 / 284\n",
      "7A/2\n",
      "29, Suite 123\n",
      "416,418\n",
      "Shop 70/46\n",
      "5/151\n",
      "210/13\n",
      "Shop 3c\n",
      "NEP 10\n",
      "Shop 14\n",
      "Gate A, 153-233\n",
      "2 Level 13\n",
      "3/1\n",
      "1/234\n",
      "1/235\n",
      "Unit 2 / 1\n",
      "28/12-14\n",
      "Shop 4, 14\n",
      "5/654\n",
      "10/17\n"
     ]
    }
   ],
   "source": [
    "# Searching for problem chars in the attribute value, v, of tags.\n",
    "def is_housenumber(elem):\n",
    "    return (elem.tag == \"tag\") and (elem.attrib['k'] == \"addr:housenumber\")\n",
    "\n",
    "problemhousenumbers = set()\n",
    "for event, elem in ET.iterparse(filename):\n",
    "    if is_housenumber(elem):\n",
    "        v = elem.attrib['v']\n",
    "        if problem_chars.search(v):\n",
    "            problemhousenumbers.add(v)\n",
    "        \n",
    "#problemhousenumbers\n",
    "print \"Printing the first 50 results:\"\n",
    "for i, phn in enumerate(problemhousenumbers):\n",
    "    if i < 50:\n",
    "        print phn\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that most apartments are represented in the '3/42' format. Sometimes these numbers are separated by commas, but commas are also used in some cases to form lists. This makes it difficult to extract apartment numbers by looking for commas. The best way to create the most uniformity is to split all housenumbers with a slash, '/', and create a field called `unitnumber`. We can also change the name of the `housenumber` field to `streetnumber` which is a more common terminology in Australia.\n",
    "\n",
    "## Data Wrangling\n",
    "We can now process the XML dataset to produce a cut-down JSON document with only the information we want. As we process each element, we will shape the data to take the form we would like it to have in the database. \n",
    "\n",
    "As we process the data, we will ignore all elements whose attributes contain problem characters or more than one colon. We will use a dictionary to form a mapping between street type abbreviations and the full name and we will split `housenumber` to form `unitnumber` and `streetnumber`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "import json\n",
    "\n",
    "mapping = { \"St\": \"Street\",\n",
    "            \"St.\": \"Street\",\n",
    "            \"street\" : \"Street\",\n",
    "            \"Streett\" : \"Street\",\n",
    "            \"st\" : \"Street\",\n",
    "            \"Ave\": \"Avenue\",\n",
    "            \"Av\" : \"Avenue\",\n",
    "            \"Rd.\": \"Road\",\n",
    "            \"Rd\" : \"Road\"\n",
    "            }\n",
    "\n",
    "street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "lower = re.compile(r'^([a-z]|_)*$')\n",
    "lower_colon = re.compile(r'^([a-z_]*):([a-z_]*)$')\n",
    "lower_slash = re.compile(r'^([a-z0-9_-]*)\\/([a-z0-9_-]*)$')\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "double_colon = re.compile(r'^([a-z]|_)*:([a-z_]*):([a-z]|_)*$')\n",
    "\n",
    "CREATED = [ \"version\", \"changeset\", \"timestamp\", \"user\", \"uid\"]\n",
    "\n",
    "\n",
    "def is_street_name(elem):\n",
    "    return (elem.attrib['k'] == \"addr:street\")\n",
    "\n",
    "\n",
    "def update_street_name(name, mapping):\n",
    "\n",
    "    m = street_type_re.search(name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type in mapping:\n",
    "            name = re.sub(street_type, mapping[street_type], name)\n",
    "\n",
    "    return name\n",
    "\n",
    "\n",
    "def shape_element(element):\n",
    "    \n",
    "    node = {}\n",
    "    if element.tag == \"node\" or element.tag == \"way\" :\n",
    "        for tag in element.iter(\"tag\"):\n",
    "            k = tag.attrib[\"k\"]\n",
    "            v = tag.attrib[\"v\"]\n",
    "            if not (re.search(problemchars, k) or\n",
    "                    re.search(double_colon, k)):\n",
    "                match = re.search(lower_colon, k)\n",
    "                \n",
    "                # Check if tag attribute has a colon amongst the lower case text\n",
    "                if match:\n",
    "                    dict_name = match.group(1)\n",
    "                    key_name = match.group(2)\n",
    "                    \n",
    "                    if dict_name == \"addr\":\n",
    "                        if \"address\" not in node:\n",
    "                            node[\"address\"] = {}\n",
    "                        if key_name == \"street\":\n",
    "                            v = update_street_name(v, mapping)\n",
    "                        if key_name == \"housenumber\":\n",
    "                            match_slash = re.search(lower_slash, v)\n",
    "                            \n",
    "                            if match_slash:\n",
    "                                node[\"address\"][\"unitnumber\"] = match_slash.group(1)\n",
    "                                node[\"address\"][\"streetnumber\"] = match_slash.group(2)\n",
    "                            else:\n",
    "                                node[\"address\"][\"streetnumber\"] = v\n",
    "                        else:\n",
    "                            node[\"address\"][key_name] = v\n",
    "                            \n",
    "                    elif (dict_name == \"is_in\") and (key_name == \"suburb\"):\n",
    "                        node[\"suburb\"] = v\n",
    "                \n",
    "                # else if only lower case text then copy as is.\n",
    "                elif re.search(lower, k):\n",
    "                    node[k] = v\n",
    "\n",
    "        # Check if any valid tags were found for this element. If not, then lets ignore it.\n",
    "        if node:\n",
    "            node[\"type\"] = element.tag\n",
    "            node[\"created\"] = {}\n",
    "            node[\"pos\"] = [0.0, 0.0]\n",
    "            for attribute in element.attrib:\n",
    "                if attribute in CREATED:\n",
    "                    node[\"created\"][attribute] = element.attrib[attribute]\n",
    "                elif attribute == \"lat\":\n",
    "                    try:\n",
    "                        node[\"pos\"][0] = float(element.attrib[\"lat\"])\n",
    "                    except:\n",
    "                        node[\"pos\"][0] = 0.0\n",
    "                elif attribute == \"lon\":\n",
    "                    try:\n",
    "                        node[\"pos\"][1] = float(element.attrib[\"lon\"])\n",
    "                    except:\n",
    "                        node[\"pos\"][1] = 0.0\n",
    "                else:\n",
    "                    node[attribute] = element.attrib[attribute]\n",
    "\n",
    "            return node\n",
    "        else:\n",
    "            return None\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def process_map(file_in, pretty = False):\n",
    "    file_out = \"{0}.json\".format(file_in)\n",
    "\n",
    "    data = []\n",
    "    with codecs.open(file_out, \"w\") as fo:\n",
    "        for _, element in ET.iterparse(file_in):\n",
    "            el = shape_element(element)\n",
    "            if el:\n",
    "                data.append(el)\n",
    "                if pretty:\n",
    "                    fo.write(json.dumps(el, indent=2)+\"\\n\")\n",
    "                else:\n",
    "                    fo.write(json.dumps(el) + \"\\n\")\n",
    "    return data\n",
    "\n",
    "data = process_map(filename, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the JSON document into MongoDB\n",
    "In MongoDB, we can create an `openstreetdata` database and then create a collection for OSM Metro dataset imported into it. In this case, we can use the following commands to create a `Sydney` collection.\n",
    "\n",
    "`$ mongo\n",
    "    > use openstreetdata\n",
    "    > db.createCollection(\"Sydney\")`\n",
    "\n",
    "Our JSON document can then be imported into the collection using mongoimport as follows:\n",
    "\n",
    "`$ mongoimport -d openstreetdata -c Sydney --type json --file sydney_australia.osm.json`\n",
    "\n",
    "## Querying The Database\n",
    "With the dataset now imported into MongoDB as a document collection, we can simply query the database to discover any location information about Sydney, Australia. For instance, we can query the dataset for all the types of amenities listed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "client = MongoClient('localhost:27017')\n",
    "db = client['openstreetdata']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of types of amenities: 163\n",
      "Printing the first 20 results:\n",
      "{u'count': 4106, u'_id': u'parking'}\n",
      "{u'count': 1414, u'_id': u'bench'}\n",
      "{u'count': 1069, u'_id': u'school'}\n",
      "{u'count': 1067, u'_id': u'restaurant'}\n",
      "{u'count': 899, u'_id': u'cafe'}\n",
      "{u'count': 828, u'_id': u'toilets'}\n",
      "{u'count': 782, u'_id': u'drinking_water'}\n",
      "{u'count': 675, u'_id': u'fast_food'}\n",
      "{u'count': 627, u'_id': u'place_of_worship'}\n",
      "{u'count': 541, u'_id': u'bicycle_parking'}\n",
      "{u'count': 481, u'_id': u'fuel'}\n",
      "{u'count': 479, u'_id': u'shelter'}\n",
      "{u'count': 452, u'_id': u'pub'}\n",
      "{u'count': 421, u'_id': u'post_box'}\n",
      "{u'count': 358, u'_id': u'post_office'}\n",
      "{u'count': 322, u'_id': u'waste_basket'}\n",
      "{u'count': 278, u'_id': u'bbq'}\n",
      "{u'count': 252, u'_id': u'bank'}\n",
      "{u'count': 237, u'_id': u'telephone'}\n",
      "{u'count': 209, u'_id': u'pharmacy'}\n"
     ]
    }
   ],
   "source": [
    "# Build the aggregation pipeline\n",
    "pipeline = [\n",
    "            {\"$match\":{\"amenity\": {\"$exists\": 1}}},\n",
    "            {\"$group\":{\"_id\":\"$amenity\",\n",
    "                       \"count\":{\"$sum\":1}}},\n",
    "            {\"$sort\": {\"count\": -1}},\n",
    "           ]\n",
    "\n",
    "result = [doc for doc in db.Sydney.aggregate(pipeline)]\n",
    "\n",
    "result_length = len(result)\n",
    "print \"Number of types of amenities: %d\" % result_length\n",
    "print \"Printing the first 20 results:\"\n",
    "for i in range(0,20):\n",
    "    print result[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains 163 types of amenities, the most prevalent of which being parking locations. We could now query the database to find all restaurants and cafes listed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of restaurants & cafes: 899\n",
      "Printing the first 10 results:\n",
      "{u'Style': u'cafe', u'_id': ObjectId('5a12762405ab824ba3ca5f6a'), u'Lat/Lon': [-33.9505592, 151.1634195]}\n",
      "{u'Style': u'cafe', u'_id': ObjectId('5a12762405ab824ba3ca6009'), u'Name': u'Centennial Park Cafe', u'Lat/Lon': [-33.8946861, 151.2333301]}\n",
      "{u'Style': u'cafe', u'_id': ObjectId('5a12762405ab824ba3ca6046'), u'Name': u'Bytes @ ATP', u'Lat/Lon': [-33.8949115, 151.1954059]}\n",
      "{u'Style': u'cafe', u'_id': ObjectId('5a12762405ab824ba3ca6047'), u'Name': u'Saint-Germaine Patisserie', u'Lat/Lon': [-33.894917, 151.1980919]}\n",
      "{u'Style': u'cafe', u'_id': ObjectId('5a12762405ab824ba3ca604f'), u'Name': u\"Bobby's Cafe\", u'Lat/Lon': [-33.8911183, 151.1958773]}\n",
      "{u'Style': u'cafe', u'_id': ObjectId('5a12762405ab824ba3ca6083'), u'Name': u'Pavilion Caf\\xe9', u'Lat/Lon': [-33.948136, 151.2564277]}\n",
      "{u'Style': u'cafe', u'_id': ObjectId('5a12762405ab824ba3ca616e'), u'Name': u'Sea Salt Cafe Kiosk', u'Lat/Lon': [-33.9143366, 151.2667604]}\n",
      "{u'Style': u'cafe', u'_id': ObjectId('5a12762405ab824ba3ca622e'), u'Lat/Lon': [-33.9035687, 151.2676732]}\n",
      "{u'Style': u'cafe', u'_id': ObjectId('5a12762405ab824ba3ca627e'), u'Lat/Lon': [-33.8887463, 151.1568007]}\n",
      "{u'Style': u'cafe', u'_id': ObjectId('5a12762405ab824ba3ca62cc'), u'Name': u'Hyde Park Cafe', u'Lat/Lon': [-33.8765639, 151.2097454]}\n"
     ]
    }
   ],
   "source": [
    "# Build the aggregation pipeline\n",
    "pipeline = [\n",
    "            {\"$match\": {\"amenity\": \"restaurant\",\n",
    "                        \"amenity\": \"cafe\"}},\n",
    "            {\"$project\": {\"Name\": \"$name\",\n",
    "                          \"Style\": \"$amenity\",\n",
    "                          \"Lat/Lon\": \"$pos\"\n",
    "                         } \n",
    "            }\n",
    "           ]\n",
    "\n",
    "result = [doc for doc in db.Sydney.aggregate(pipeline)]\n",
    "\n",
    "result_length = len(result)\n",
    "print \"Number of restaurants & cafes: %d\" % result_length\n",
    "#result\n",
    "print \"Printing the first 10 results:\"\n",
    "for i in range(0,10):\n",
    "    #print \"result[%s]\" % str(i)\n",
    "    print result[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many locations contain an address or suburb, but every one at least contains a pair of latitude/longitude coordinates. These coordinates could be used to calculate distances between points or to render the locations on a map. \n",
    "\n",
    "We could also query the database to find cinemas with wheelchair access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cinemas with wheelchair access: 7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{u'_id': ObjectId('5a12762405ab824ba3ca6359'),\n",
       "  u'lat/lon': [-33.8598082, 151.213016],\n",
       "  u'name': u'Dendy'},\n",
       " {u'_id': ObjectId('5a12762505ab824ba3caa9b2'),\n",
       "  u'lat/lon': [-33.7979086, 151.1820698]},\n",
       " {u'_id': ObjectId('5a12762505ab824ba3cab17b'),\n",
       "  u'lat/lon': [-33.9188443, 150.9233527],\n",
       "  u'name': u'Event Cinemas'},\n",
       " {u'_id': ObjectId('5a12762505ab824ba3cac2f0'),\n",
       "  u'lat/lon': [-33.8331572, 151.0860894],\n",
       "  u'name': u'Reading Cinema'},\n",
       " {u'_id': ObjectId('5a12762505ab824ba3cad288'),\n",
       "  u'lat/lon': [-33.8751736, 151.2060563],\n",
       "  u'location': u'Sydney',\n",
       "  u'name': u'Event'},\n",
       " {u'_id': ObjectId('5a12762505ab824ba3cb096d'),\n",
       "  u'lat/lon': [-33.8960846, 151.1805118],\n",
       "  u'name': u'Dendy Newtown'},\n",
       " {u'_id': ObjectId('5a12762505ab824ba3cb0a7f'),\n",
       "  u'lat/lon': [-33.7967566, 151.1830424]}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the aggregation pipeline\n",
    "pipeline = [\n",
    "            {\"$match\":{\"amenity\": \"cinema\",\n",
    "                       \"wheelchair\": {\"$eq\": 'yes'}}},\n",
    "            {\"$project\": {\"name\": \"$name\",\n",
    "                          \"location\": \"$address.city\",\n",
    "                          \"suburb\": \"$suburb\",\n",
    "                          \"lat/lon\": \"$pos\"\n",
    "                         } \n",
    "            }\n",
    "           ]\n",
    "\n",
    "result = [doc for doc in db.Sydney.aggregate(pipeline)]\n",
    "\n",
    "result_length = len(result)\n",
    "print \"Number of cinemas with wheelchair access: %d\" % result_length\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "This notebook has demonstrated an application of data wrangling where free mapping data accessible from the OpenStreetMap project in the form of XML data, can be wrangled and processed using standard Python libraries and then loaded into a MongoDB database as a collection of JSON documents. This data can now be used as a backend for a mapping application without needing to use a commercial, propriety mapping service such as Google Maps."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
